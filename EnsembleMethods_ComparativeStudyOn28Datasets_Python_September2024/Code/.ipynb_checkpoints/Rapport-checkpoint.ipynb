{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c57061a-68a6-43a6-a282-badd09bc90f0",
   "metadata": {},
   "source": [
    "# **<center>Étude Comparative Des Méthodes D'Ensemble Et Des Techniques De Rééquilibrage Pour La Classification De Données Déséquilibrées</center>**\n",
    "\n",
    "---\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dad4415-bfb5-44f9-988e-593f8e7e86d0",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015c436f-9b03-45c1-b139-58923e93f4ef",
   "metadata": {},
   "source": [
    "Dans le domaine de l'apprentissage automatique, la classification de données déséquilibrées reste un défi majeur. Ce déséquilibre, caractérisé par une représentation inégale des classes dans un ensemble de données, peut significativement affecter les performances des algorithmes de classification standard. Notre étude se concentre sur l'évaluation et la comparaison de diverses méthodes d'ensemble et non-ensemble, ainsi que sur l'application de techniques de rééquilibrage, pour aborder ce problème.\n",
    "\n",
    "Nous avons analysé 28 jeux de données présentant divers degrés de déséquilibre, allant de datasets relativement équilibrés à des cas extrêmes où une classe représente moins de 0.1% des échantillons. Les principales difficultés rencontrées incluent :\n",
    "\n",
    "- La variabilité des datasets bruts: Richesse en nombre d'observations (de 132 à 45 211 instances), en nombre de caractéristiques (de 5 à 91 variables) et en travail exploratoire nécéssaire à leur preprocessing.\n",
    "  \n",
    "- La multiplicité d'approches possibles de l'exercice: chaque étape offrait une multitude de méthodes possibles pour la famille d'algorithme et les ajustements potentiels.\n",
    "  \n",
    "- Choix d'implémentation: La librairie scikit-learn a été retenue pour l'essentiel de l'implémentation , mais ça n'a pas été un choix évident. En effet sklearn n'adapte pas nativement les calcul sur le GPU. Il existe certes une possiblité de requisitionner plusieurs coeurs du CPU avec le paramètre \"n_jobs\", mais ça reste insuffissant pour des tâches gourmandes en ressources et ça peut rapidement bloquer l'expérimentation. Des tests avec d'autres librairies n'ont pas été concluants car les méthodes manquaient de compatibilité et reduisaient la lisibilité du code.\n",
    "\n",
    "Notre objectif est d'évaluer l'efficacité de différentes approches pour améliorer la classification sur ces datasets déséquilibrés, en mettant l'accent sur les méthodes d'ensemble et les techniques de rééquilibrage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7747535-2ce7-4a34-bb15-7e248e6c3b51",
   "metadata": {},
   "source": [
    "## 2. Méthodologie\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e1be95-1d4f-464a-b075-14ca311aaaef",
   "metadata": {},
   "source": [
    "### 2.1 Notations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd99001b-42cd-443e-ade0-b52f6791de9c",
   "metadata": {},
   "source": [
    "Avant de présenter les méthodes d'ensemble, définissons les notations utilisées :\n",
    "\n",
    "* $D$ : Ensemble de données complet (dataset)\n",
    "* $D_i$ : Sous-ensemble (échantillon) du dataset $D$\n",
    "* $X$ : Matrice des caractéristiques, où $X_{i,j}$ représente la $j$-ème caractéristique du $i$-ème échantillon\n",
    "* $y$ : Vecteur des étiquettes de classe, où $y_i \\in \\{0, 1\\}$\n",
    "* $h(X)$ : Fonction de prédiction d'un classifieur\n",
    "* $w_i$ : Poids attribué à l'échantillon $i$\n",
    "* $N$ : Nombre total d'échantillons\n",
    "* $N_+$ : Nombre d'échantillons de la classe minoritaire (positive)\n",
    "* $N_-$ : Nombre d'échantillons de la classe majoritaire (négative)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92687cff-b835-42ca-8d61-58d86fdaadca",
   "metadata": {},
   "source": [
    "### 2.2 Mesures de performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48d8511-5272-41dc-81cf-0602d656d32f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Notre étude se concentre principalement sur l'optimisation du rappel (recall) et de l'aire sous la courbe précision-rappel (AUC-PR), particulièrement pertinentes pour les problèmes de classification déséquilibrée. Ces métriques sont choisies pour leur capacité à évaluer efficacement les performances sur la classe minoritaire, souvent la plus importante dans les problèmes déséquilibrés.\n",
    "\n",
    "• **Matrice de confusion** :\n",
    "  Avant de définir nos métriques, rappelons les éléments de la matrice de confusion :\n",
    "  - $TP$ (True Positives) : Vrais Positifs\n",
    "  - $TN$ (True Negatives) : Vrais Négatifs\n",
    "  - $FP$ (False Positives) : Faux Positifs\n",
    "  - $FN$ (False Negatives) : Faux Négatifs\n",
    "\n",
    "• **Rappel (Recall)** :\n",
    "  $$ \\text{Rappel} = \\frac{TP}{TP + FN} $$\n",
    "  \n",
    "  Le rappel mesure la proportion d'instances positives correctement identifiées. Dans un contexte déséquilibré, un rappel élevé indique une bonne détection de la classe minoritaire.\n",
    "\n",
    "• **Précision** :\n",
    "  $$ \\text{Précision} = \\frac{TP}{TP + FP} $$\n",
    "  \n",
    "  La précision mesure la proportion de prédictions positives qui sont correctes. Elle est importante pour évaluer la fiabilité des prédictions positives.\n",
    "\n",
    "• **Ratio Précision/Rappel** :\n",
    "  Le compromis entre précision et rappel est crucial dans les ensembles déséquilibrés :\n",
    "  - Un rappel élevé avec une faible précision indique de nombreux faux positifs.\n",
    "  - Une précision élevée avec un faible rappel suggère de nombreux faux négatifs.\n",
    "  - L'objectif est souvent de maximiser le rappel tout en maintenant une précision acceptable.\n",
    "\n",
    "• **Courbe Précision-Rappel** :\n",
    "  1. Calculer précision et rappel pour différents seuils de classification.\n",
    "  2. Tracer la précision en fonction du rappel.\n",
    "  3. La courbe illustre le compromis entre précision et rappel à mesure que le seuil de classification varie.\n",
    "\n",
    "• **AUC-PR** (Aire sous la courbe Précision-Rappel) :\n",
    "  $$ AUC-PR = \\int_0^1 p(r) dr $$\n",
    "  où $p$ est la précision et $r$ est le rappel.\n",
    "\n",
    "  Calcul pratique pour un ensemble fini de points $(r_1, p_1), ..., (r_n, p_n)$ ordonnés par rappel croissant :\n",
    "  $$ AUC-PR \\approx \\sum_{i=1}^{n-1} (r_{i+1} - r_i) \\frac{p_i + p_{i+1}}{2} $$\n",
    "\n",
    "  Étapes de calcul :\n",
    "  1. Trier les prédictions par score décroissant.\n",
    "  2. Calculer précision et rappel pour chaque seuil.\n",
    "  3. Calculer l'aire sous la courbe en utilisant la méthode des trapèzes.\n",
    "\n",
    "• **Importance pour les ensembles déséquilibrés** :\n",
    "  - L'AUC-PR est préférée à l'AUC-ROC car elle est plus sensible aux performances sur la classe minoritaire.\n",
    "  - Elle n'est pas affectée par le grand nombre de vrais négatifs typiques des problèmes déséquilibrés.\n",
    "  - Elle permet une évaluation plus nuancée des performances, particulièrement lorsque la détection précise de la classe minoritaire est cruciale.\n",
    "\n",
    "L'utilisation combinée du rappel et de l'AUC-PR nous permet d'optimiser nos modèles pour une détection efficace de la classe minoritaire tout en maintenant un équilibre avec la précision globale, ce qui est essentiel dans de nombreuses applications réelles impliquant des données déséquilibrées."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ca84fb-1f14-4b91-90be-5f19f0667a7c",
   "metadata": {},
   "source": [
    "### 2.3 Algorithmes et techniques étudiés"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9952ce58-81f0-44c8-9484-a2f20bbfced4",
   "metadata": {},
   "source": [
    "#### 2.3.1 Méthodes de base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f990ee6-2796-4b18-a27f-c31799808a8b",
   "metadata": {},
   "source": [
    "\n",
    "Dans notre étude, nous avons examiné plusieurs méthodes de classification fondamentales, chacune apportant ses propres forces à la tâche de classification des données déséquilibrées :\n",
    "\n",
    "• **Régression logistique** \n",
    "  - Modèle linéaire simple mais puissant\n",
    "  - Efficace pour comprendre l'impact de chaque caractéristique\n",
    "  - Fournit des probabilités facilement interprétables\n",
    "\n",
    "• **SVM linéaire** \n",
    "  - Cherche l'hyperplan optimal séparant les classes\n",
    "  - Performant dans les espaces à haute dimension\n",
    "  - Robuste face au surapprentissage dans de nombreux cas\n",
    "\n",
    "• **Arbre de décision** \n",
    "  - Modèle intuitif basé sur une série de décisions\n",
    "  - Capable de capturer des relations non linéaires\n",
    "  - Facile à interpréter et à visualiser\n",
    "\n",
    "• **k-plus proches voisins (k-NN)** \n",
    "  - Méthode non paramétrique basée sur la proximité\n",
    "  - Simple à mettre en œuvre et à comprendre\n",
    "  - Efficace pour les frontières de décision complexes\n",
    "\n",
    "• **Perceptron multicouche (MLP)** \n",
    "  - Réseau de neurones capable d'apprendre des patterns complexes\n",
    "  - Peut modéliser des relations hautement non linéaires\n",
    "  - Adaptable à une grande variété de problèmes\n",
    "\n",
    "Ces méthodes de base constituent le fondement de notre analyse, nous permettant d'établir des points de comparaison solides pour évaluer l'efficacité des techniques plus avancées sur nos ensembles de données déséquilibrées."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d21c19-6f9b-4fe2-8101-9b796039ac71",
   "metadata": {},
   "source": [
    "#### 2.3.2 Méthodes d'ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d3dacf-0cae-4efe-be19-794667e24b13",
   "metadata": {},
   "source": [
    "Les méthodes d'ensemble, combinant plusieurs modèles pour améliorer les performances globales, sont théoriquement efficaces pour traiter les problèmes de classification déséquilibrée. Voici les techniques que nous avons vues en cours et que nous avons explorées, chacune avec un pseudocode simplifié de son fonctionnement :\n",
    "\n",
    "\n",
    "• **Bagging** \n",
    "  - Crée plusieurs sous-ensembles de données par échantillonnage avec remplacement\n",
    "  - Réduit la variance et aide à prévenir le surapprentissage\n",
    "  - Particulièrement utile pour stabiliser des modèles instables comme les arbres de décision\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& \\text{Pour } i = 1 \\text{ à } N: \\\\\n",
    "& \\quad D_i = \\text{ÉchantillonAvecRemplacement}(D) \\\\\n",
    "& \\quad M_i = \\text{EntraînerModèle}(D_i) \\\\\n",
    "& \\text{Prédiction}(x) = \\frac{1}{N}\\sum_{i=1}^N M_i(x) \\text{ ou } \\text{VoteMajoritaire}(\\{M_i(x)\\}_{i=1}^N)\n",
    "\\end{aligned}\n",
    "$$\n",
    "<br>\n",
    "\n",
    "• **Random Forest** \n",
    "  - Ensemble d'arbres de décision avec sélection aléatoire de caractéristiques\n",
    "  - Offre un bon équilibre entre biais et variance\n",
    "  - Robuste face au bruit et aux valeurs aberrantes\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& \\text{Pour } i = 1 \\text{ à } N: \\\\\n",
    "& \\quad D_i = \\text{ÉchantillonAvecRemplacement}(D) \\\\\n",
    "& \\quad F_i = \\text{SélectionAléatoireCaractéristiques}(F, m) \\\\\n",
    "& \\quad T_i = \\text{EntraînerArbreDécision}(D_i, F_i) \\\\\n",
    "& \\text{Prédiction}(x) = \\text{VoteMajoritaire}(\\{T_i(x)\\}_{i=1}^N)\n",
    "\\end{aligned}\n",
    "$$\n",
    "<br>\n",
    "\n",
    "• **Stacking** \n",
    "  - Combine les prédictions de plusieurs modèles via un méta-apprenant\n",
    "  - Permet d'exploiter les forces de différents types de modèles\n",
    "  - Peut capturer des relations complexes en combinants  les apprenants de base\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& M_1, M_2, \\ldots, M_K = \\text{EntraînerModèlesBase}(D_\\text{train}) \\\\\n",
    "& \\text{Pour } x_i \\in D_\\text{validation}: \\\\\n",
    "& \\quad z_i = [M_1(x_i), M_2(x_i), \\ldots, M_K(x_i)] \\\\\n",
    "& M_F = \\text{EntraînerMétaModèle}(\\{(z_i, y_i)\\}_{i=1}^N) \\\\\n",
    "& \\text{Prédiction}(x) = M_F([M_1(x), M_2(x), \\ldots, M_K(x)])\n",
    "\\end{aligned}\n",
    "$$\n",
    "<br>\n",
    "\n",
    "• **AdaBoost** \n",
    "  - Focalise l'apprentissage sur les exemples difficiles à classer\n",
    "  - Attribue des poids plus élevés aux classifieurs performants\n",
    "  - Efficace pour améliorer les performances des classifieurs faibles\n",
    "\n",
    "AdaBoost (Adaptive Boosting) est un algorithme d'ensemble qui illustre bien le principe d'apprentissage sensible au coût. Il ajuste itérativement les poids des exemples d'entraînement en fonction de leur difficulté de classification. Voici l'algorithme détaillé :\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& w_i^{(1)} = \\frac{1}{n}, \\quad i = 1,\\ldots,n \\\\\n",
    "& \\text{Pour } t = 1 \\text{ à } T: \\\\\n",
    "& \\quad h_t = \\text{EntraînerClassifieurFaible}(D, w^{(t)}) \\\\\n",
    "& \\quad \\epsilon_t = \\sum_{i=1}^n w_i^{(t)} \\mathbb{1}[h_t(x_i) \\neq y_i] \\\\\n",
    "& \\quad \\alpha_t = \\frac{1}{2} \\ln\\left(\\frac{1-\\epsilon_t}{\\epsilon_t}\\right) \\\\\n",
    "& \\quad w_i^{(t+1)} = w_i^{(t)} \\exp(-\\alpha_t y_i h_t(x_i)) \\\\\n",
    "& \\quad w^{(t+1)} = \\frac{w^{(t+1)}}{\\sum_{i=1}^n w_i^{(t+1)}} \\\\\n",
    "& \\text{Prédiction}(x) = \\text{sign}\\left(\\sum_{t=1}^T \\alpha_t h_t(x)\\right)\n",
    "\\end{aligned}\n",
    "$$\n",
    "Avec :\n",
    "- $T$ : Nombre total d'itérations (nombre de classifieurs faibles)\n",
    "- $w_i^{(t)}$ : Poids de l'échantillon $i$ à l'itération $t$\n",
    "- $h_t$ : Classifieur faible à l'itération $t$\n",
    "- $\\epsilon_t$ : Erreur pondérée du classifieur faible $h_t$\n",
    "- $\\alpha_t$ : Coefficient d'importance du classifieur faible $h_t$\n",
    "- $x_i$ : Vecteur de caractéristiques de l'échantillon $i$\n",
    "- $y_i$ : Étiquette réelle de l'échantillon $i$ (généralement $\\{-1, +1\\}$ pour AdaBoost)\n",
    "- $\\mathbb{1}[.]$ : Fonction indicatrice (1 si la condition est vraie, 0 sinon)\n",
    "\n",
    "<br>\n",
    "\n",
    "• **Gradient Boosting** \n",
    "  - Construit des modèles séquentiellement pour corriger les erreurs des précédents\n",
    "  - Réputé efficace dans la communauté\n",
    "  - applicable différents types de données et de problèmes\n",
    "\n",
    "L'algorithme du Gradient Boosting peut être décrit mathématiquement comme suit :\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& F_0(X) = \\arg\\min_\\gamma \\sum_{i=1}^N L(y_i, \\gamma) \\\\\n",
    "& \\text{Pour } m = 1 \\text{ à } M: \\\\\n",
    "& \\quad r_{im} = -\\left[\\frac{\\partial L(y_i, F(X_i))}{\\partial F(X_i)}\\right]_{F=F_{m-1}} \\\\\n",
    "& \\quad h_m = \\arg\\min_h \\sum_{i=1}^N (r_{im} - h(X_i))^2 \\\\\n",
    "& \\quad \\gamma_m = \\arg\\min_\\gamma \\sum_{i=1}^N L(y_i, F_{m-1}(X_i) + \\gamma h_m(X_i)) \\\\\n",
    "& \\quad F_m(X) = F_{m-1}(X) + \\eta \\gamma_m h_m(X) \\\\\n",
    "& \\text{Prédiction}(X) = F_M(X)\n",
    "\\end{aligned}\n",
    "$$\n",
    "Avec :\n",
    "\n",
    "- $M$ : Le nombre total d'itérations (arbres)\n",
    "- $F_m(X)$ : Le modèle à l'itération $m$\n",
    "- $L(y_i, F(X_i))$ : La fonction de perte qui mesure l'écart entre la prédiction $F(X_i)$ et la vraie valeur $y_i$\n",
    "- $r_{im}$ : Le résidu (gradient négatif de la fonction de perte) pour l'échantillon $i$ à l'itération $m$\n",
    "- $h_m(X)$ : Le modèle faible (généralement un arbre de décision) à l'itération $m$\n",
    "- $\\gamma_m$ : Le coefficient de pondération optimal pour le modèle faible $h_m$\n",
    "- $\\eta$ : Le taux d'apprentissage (learning rate)\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "• **XGBoost** \n",
    "  - Implémentation optimisée du gradient boosting\n",
    "  - Réputé offrir une excellente performance et vitesse selon la littérature\n",
    "  - Intègre des techniques de régularisation pour prévenir le surapprentissage\n",
    "\n",
    "L'algorithme XGBoost peut être décrit mathématiquement comme suit :\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& F_0(X) = 0 \\\\\n",
    "& \\text{Pour } m = 1 \\text{ à } M: \\\\\n",
    "& \\quad g_i = \\left[\\frac{\\partial L(y_i, F(X_i))}{\\partial F(X_i)}\\right]_{F=F_{m-1}} \\\\\n",
    "& \\quad h_i = \\left[\\frac{\\partial^2 L(y_i, F(X_i))}{\\partial F(X_i)^2}\\right]_{F=F_{m-1}} \\\\\n",
    "& \\quad T_m = \\arg\\max_T \\left[\\frac{1}{2} \\sum_{j=1}^T \\frac{(\\sum_{i \\in I_j} g_i)^2}{\\sum_{i \\in I_j} h_i + \\lambda} - \\gamma T\\right] \\\\\n",
    "& \\quad F_m(X) = F_{m-1}(X) + \\eta T_m(X) \\\\\n",
    "& \\text{Prédiction}(X) = F_M(X)\n",
    "\\end{aligned}\n",
    "$$\n",
    "Avec :\n",
    "\n",
    "- $M$ : Le nombre total d'itérations (arbres)\n",
    "- $F_m(X)$ : Le modèle à l'itération $m$\n",
    "- $L(y_i, F(X_i))$ : La fonction de perte qui mesure l'écart entre la prédiction $F(X_i)$ et la vraie valeur $y_i$\n",
    "- $g_i$ : Le gradient de premier ordre de la fonction de perte pour l'échantillon $i$\n",
    "- $h_i$ : Le gradient de second ordre (Hessien) de la fonction de perte pour l'échantillon $i$\n",
    "- $T_m$ : L'arbre de décision construit à l'itération $m$\n",
    "- $I_j$ : L'ensemble des indices des échantillons dans la feuille $j$ de l'arbre\n",
    "- $\\lambda$ : Le paramètre de régularisation L2 sur les poids des feuilles\n",
    "- $\\gamma$ : Le paramètre de régularisation sur la complexité de l'arbre (nombre de feuilles)\n",
    "- $\\eta$ : Le taux d'apprentissage (learning rate)\n",
    "\n",
    "<br>\n",
    "\n",
    "Nous allons tester ces différentes méthodes d'ensemble pour nous permettre d'observer expérimentalement leurs qualités certaines sur le plan mathématique et théorique. Elles sont censées nous offrir une meilleure généralisation et une robustesse face aux déséquilibres de classes. Leur capacité à combiner différentes perspectives d'apprentissage les rend candidates intérressantes à notre problématique de classification de données déséquilibrées."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef85680-5590-42bc-8f1c-4cde31c6556e",
   "metadata": {},
   "source": [
    "#### 2.3.3 Techniques de rééquilibrage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840f617e-b6a7-490d-86de-3add9adb46cf",
   "metadata": {},
   "source": [
    "\n",
    "Dans cette quête d'extraire le maximum d'information de données déséquilibrées, nous avons exploré deux approches principales pour gérer le déséquilibre des classes : l'apprentissage sensible au coût et le rééchantillonnage avec SMOTE.\n",
    "<br>\n",
    "**A. Apprentissage sensible au coût**\n",
    "\n",
    "L'apprentissage sensible au coût est une approche qui modifie le processus d'apprentissage pour prendre en compte le déséquilibre des classes sans altérer la distribution des données d'entrée.\n",
    "\n",
    "\n",
    "**Principe :**\n",
    "Cette méthode attribue des poids aux classes inversement proportionnels à leur fréquence dans les données d'entraînement. Ainsi, les erreurs sur les classes minoritaires sont plus pénalisées que celles sur les classes majoritaires.\n",
    "\n",
    "\n",
    "**Exemple simple de Formule de calcul des poids :**\n",
    "$$ w_j = \\frac{n}{k n_j} $$\n",
    "où :\n",
    "- $w_j$ est le poids attribué à la classe $j$\n",
    "- $n$ est le nombre total d'échantillons\n",
    "- $k$ est le nombre total de classes\n",
    "- $n_j$ est le nombre d'échantillons de la classe $j$\n",
    "\n",
    "\n",
    "**Fonctionnement :**\n",
    "1. Les poids sont calculés pour chaque classe selon la formule ci-dessus.\n",
    "2. Ces poids sont intégrés dans la fonction de perte de l'algorithme d'apprentissage.\n",
    "3. Lors de l'entraînement, les erreurs sur les classes minoritaires ont un impact plus important sur la fonction de perte, poussant le modèle à y accorder plus d'attention.\n",
    "\n",
    "\n",
    "**Avantages :**\n",
    "- Ne modifie pas la distribution des données d'entrée\n",
    "- Peut être appliqué à de nombreux algorithmes de classification\n",
    "- Particulièrement utile lorsque le coût d'une mauvaise classification varie selon les classes\n",
    "\n",
    "\n",
    "**Implémentation :**\n",
    "De nombreux algorithmes de scikit-learn intègrent cette approche via des paramètres spécifiques. Voici un exemple avec RandomForestClassifier, ou l'on calcule nous même les poids à attribuer aux classes avant de les donner en paramètre au classifieur :\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Calcul manuel des poids\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weight_dict = dict(zip(np.unique(y), class_weights))\n",
    "\n",
    "# Création et entraînement du modèle avec les poids calculés\n",
    "rf_cost_sensitive = RandomForestClassifier(class_weight=class_weight_dict, random_state=42)\n",
    "rf_cost_sensitive.fit(X, y)\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "**B. SMOTE (Synthetic Minority Over-sampling Technique)**\n",
    "\n",
    "SMOTE est une technique de sur-échantillonnage qui génère des exemples synthétiques de la classe minoritaire pour équilibrer le jeu de données.\n",
    "\n",
    "\n",
    "**Principe :**\n",
    "SMOTE crée de nouveaux exemples de la classe minoritaire en interpolant entre des exemples existants et leurs plus proches voisins.\n",
    "\n",
    "\n",
    "**Algorithme :**\n",
    "1. Pour chaque exemple de la classe minoritaire :\n",
    "   a. Trouver ses k plus proches voisins (typiquement k=5)\n",
    "   b. Sélectionner aléatoirement l'un de ces voisins\n",
    "   c. Créer un nouvel exemple synthétique par interpolation linéaire\n",
    "\n",
    "\n",
    "**Formule de génération :**\n",
    "$$ x_\\text{new} = x_i + \\lambda (x_\\text{neighbor} - x_i) $$\n",
    "où :\n",
    "- $x_i$ est l'exemple de la classe minoritaire\n",
    "- $x_\\text{neighbor}$ est l'un de ses k plus proches voisins\n",
    "- $\\lambda \\in [0,1]$ est un nombre aléatoire\n",
    "\n",
    "\n",
    "**Avantages :**\n",
    "- Augmente la représentation de la classe minoritaire sans simple duplication\n",
    "- Peut améliorer la généralisation du modèle\n",
    "- Utile lorsque la collecte de nouvelles données réelles est difficile ou coûteuse\n",
    "\n",
    "\n",
    "**Implémentation :**\n",
    "Nous avons utilisé l'implémentation de SMOTE fournie par la bibliothèque imbalanced-learn, en l'intégrant bien sûr à un pipeline :\n",
    "\n",
    "\n",
    "```python\n",
    "# Exemple simplifié d'utilisation de la technique smote en python\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "Ces deux techniques offrent des approches complémentaires pour traiter le déséquilibre des classes. L'apprentissage sensible au coût modifie le processus d'apprentissage lui-même, tandis que SMOTE modifie la distribution des données d'entrée. Le choix entre ces méthodes, ou leur combinaison, dépend des caractéristiques spécifiques du jeu de données et des exigences du problème de classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a029d435-3244-434e-a5da-db76da6ad504",
   "metadata": {},
   "source": [
    "### 2.4 Approche proposée"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44436f4-b346-47f2-a0e4-70d7a5ebaf08",
   "metadata": {},
   "source": [
    "Notre approche consiste à appliquer systématiquement ces méthodes sur l'ensemble des 28 datasets, en utilisant trois configurations principales:\n",
    "\n",
    "- Méthodes de base et d'ensemble sans rééquilibrage\n",
    "- Méthodes avec application de SMOTE\n",
    "- Méthodes avec pondération des classes\n",
    "  \n",
    "Nous choisirons par la suite deux méthodes qui monterent de bonnes capacités et on essayera de pousser leur ajustement pour avoir le meilleur résultat possible.\n",
    "\n",
    "Pour chaque configuration, nous utilisons la validation croisée stratifiée pour optimiser les hyper-paramètres clés de chaque algorithme. Voici un pseudo-code simplifié de notre approche :\n",
    "\n",
    "```\n",
    "Pour chaque dataset D dans l'ensemble des datasets:\n",
    "    Diviser D en ensembles d'entraînement (80%) et de test (20%)\n",
    "    Pour chaque méthode M (basique ou ensembliste):\n",
    "        Pour chaque configuration C (sans rééquilibrage, SMOTE, pondération):\n",
    "            Appliquer C à l'ensemble d'entraînement\n",
    "            Optimiser les hyper-paramètres de M par validation croisée\n",
    "            Entraîner M sur l'ensemble d'entraînement complet\n",
    "            Évaluer M sur l'ensemble de test\n",
    "            Enregistrer les performances (rappel, AUC-PR, etc.)\n",
    "```\n",
    "\n",
    "Cette approche nous permet d'évaluer systématiquement l'efficacité de chaque méthode et technique de rééquilibrage sur une variété de datasets présentant différents degrés de déséquilibre.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Points clefs de l'implémentation :**\n",
    "\n",
    "- **Validation croisée** : Nous utilisons la validation croisée à 5 plis, stratifiée, pour garder les mêmes proportions de classe dans chaque fold.\n",
    "  \n",
    "- **Pipeline scaler-classifier** : permettant la normalisation de chaque fold séparément lors de la cross validation, et une normalisation de l'ensemble lors de la phase test finale.\n",
    "\n",
    "  \n",
    "- **Métriques d'évaluation** : Outre le rappel et l'AUC-PR, nous calculons également toutes les métriques dérivées de la matrice de confusion , ainsi qu'une estimation du coût computationnel en temps de calcul et en mémoire.\n",
    "  \n",
    "- **Comparativité** : Pour assurer la robustesse des comparaisons, un nombre d'itéartions de 100 est fixé pour les algorithmes itératifs. Pour les autres, nous avons essayé de garder une équivalence de complexité du modèle par rapport à d'autres hyper-paramètres, comme la profondeur maximale d'un arbre, ou le nombre d'estimateurs dans un bagging.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b113bee6-de77-4d45-a1b6-825d2d2dd470",
   "metadata": {},
   "source": [
    "## 3. Protocole expérimental\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec345624-6ae3-4b17-98c2-d6914bad5f50",
   "metadata": {},
   "source": [
    "### 3.1 Données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604ef685-9b50-4eff-86a9-494672bc3a61",
   "metadata": {},
   "source": [
    "Notre étude s'appuie sur un ensemble diversifié de 28 jeux de données, provenant de différents domaines et présentant divers niveaux de déséquilibre. Ces datasets sont issus de vrais données de sources reconnues dans le domaine de l'apprentissage automatique. Certains datasets sont des dérivés synthétiques des originaux, à des fins académiques. Voici un aperçu de quelques-uns de ces datasets après preprocessing, illustrant la variété des problèmes abordés :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976db142-6200-4dbb-8093-21795869b380",
   "metadata": {},
   "source": [
    "| Nom du dataset | Taille d'échantillon | Nombre de caractéristiques | Ratio de classe minoritaire | Domaine |\n",
    "|----------------|----------------------|----------------------------|---------------------------|---------|\n",
    "| Hayes | 69 | 3 | 43.48% | Sociologie (statut marital) |\n",
    "| Sonar | 208 | 60 | 46.63% | Protection civile (détection de mines) |\n",
    "| Iono | 350 | 33 | 35.71% | Physique (qualité de retour radar) |\n",
    "| Spambase | 4206 | 57 | 39.90% | NLP (détection de spams) |\n",
    "| Yeast3 | 1453 | 8 | 11.15% | Biochimie (localisation cellulaire de protéines) |\n",
    "| Wine | 178 | 13 | 33.10% | Agronomie (terroir du vin) |\n",
    "| Libras | 330 | 85 | 7.27% | Hand Talk (reconnaissance du geste) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ffae88-6e48-4472-8051-a55d6ecdd2fc",
   "metadata": {},
   "source": [
    "### 3.2 Prétraitement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e07737-dbac-4986-b935-8de4ddae130c",
   "metadata": {},
   "source": [
    "La qualité et la pertinence des données sont essentielles pour la validité de notre étude. Nous avons donc implémenté un protocole de prétraitement rigoureux et adaptable, tenant compte des particularités de chaque jeu de données. Les étapes principales de notre méthodologie sont les suivantes :\n",
    "\n",
    "- **Détection et suppression des doublons** : Nous avons effectué une analyse systématique pour identifier et éliminer les observations dupliquées dans chaque jeu de données.\n",
    "\n",
    "- **Élimination des variables non informatives** : Les colonnes présentant une variance nulle ou quasi-nulle ont été identifiées et supprimées. Ces variables, n'apportant aucune information discriminante, risquaient de diminuer l'efficacité de nos modèles de classification. Mathématiquement, soit $X = [X_1, X_2, ..., X_p]$ notre dataset de features avec $p$ variables et $N$ observations. Pour chaque variable $X_j$ où $j \\in \\{1, ..., p\\}$, nous avons calculé la variance :\n",
    "\n",
    "  $\\text{Var}(X_j) = \\frac{1}{N-1} \\sum_{i=1}^N (x_{ij} - \\bar{x_j})^2$\n",
    "\n",
    "  où $x_{ij}$ est la $i$-ème observation de la $j$-ème variable, et $\\bar{x_j}$ est la moyenne de $X_j$. Les variables avec $\\text{Var}(X_j) \\approx 0$ ont été éliminées.\n",
    "\n",
    "- **Réduction de la multicolinéarité** : Nous avons détecté les colonnes hautement corrélées et conservé un seul représentant de chaque groupe. Cette approche vise à réduire la complexité du modèle tout en préservant l'information pertinente. Mathématiquement, pour chaque paire de variables $(X_j, X_k)$ où $j, k \\in \\{1, ..., p\\}$ et $j \\neq k$, nous avons calculé le coefficient de corrélation de Pearson :\n",
    "\n",
    "  $r_{jk} = \\frac{\\sum_{i=1}^N (x_{ij} - \\bar{x_j})(x_{ik} - \\bar{x_k})}{\\sqrt{\\sum_{i=1}^N (x_{ij} - \\bar{x_j})^2 \\sum_{i=1}^N (x_{ik} - \\bar{x_k})^2}}$\n",
    "\n",
    "  où $x_{ij}$ et $x_{ik}$ sont respectivement les $i$-èmes observations des variables $X_j$ et $X_k$, et $\\bar{x_j}$ et $\\bar{x_k}$ sont leurs moyennes respectives. Lorsque $|r_{jk}| > 0.999$, nous avons conservé seulement l'une des deux variables.\n",
    "\n",
    "- **Normalisation des données** : Afin d'assurer la comparabilité des variables, nous avons appliqué une normalisation via RobustScaler. Cette méthode a été choisie pour sa robustesse face aux valeurs extrêmes fréquentes dans notre cas. Pour chaque feature $X_j$, la transformation est définie comme suit :\n",
    "\n",
    "  $X_{j,scaled} = \\frac{X_j - Q_1(X_j)}{Q_3(X_j) - Q_1(X_j)}$\n",
    "\n",
    "  où $Q_1(X_j)$ et $Q_3(X_j)$ sont respectivement le premier et le troisième quartile de $X_j$.\n",
    "\n",
    "- **Traitement des outliers** : Nous avons opté pour la conservation des valeurs aberrantes. Ce choix est motivé par leur fréquence élevée qui aurait demandé un temps disproportionné à les étudier au cas par cas. Notons que dans un contexte de déséquilibre des classes, ces outliers peuvent représenter un potentiel d'information pertinente dans la classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337132b7-ca3d-4a13-91e9-c58f4cb9e231",
   "metadata": {},
   "source": [
    "### 3.3 Configuration d'ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785a14cb-abfa-4145-a7bd-6383db3470bd",
   "metadata": {},
   "source": [
    "Pour garantir la rigueur et la reproductibilité de notre étude, nous avons établi un protocole expérimental aussi robuste que possible. Les composantes clés de notre configuration sont les suivantes :\n",
    "\n",
    "- **Partitionnement des données** :\n",
    "\n",
    "  Nous avons alloué 80% des données à l'ensemble d'entraînement et 20% à l'ensemble de test. Cette répartition a été effectuée de manière stratifiée pour préserver la distribution des classes dans chaque sous-ensemble.\n",
    "\n",
    "\n",
    "- **Validation croisée** :\n",
    "\n",
    "  Une validation croisée à 5 plis, également stratifiée, a été implémentée pour ajuster entre 1 et plusieurs hyperparamètres pertinents pour l'algorithme appliqué.\n",
    "\n",
    "\n",
    "- **Métriques d'évaluation** :\n",
    "\n",
    "  Un ensemble complet de métriques a été utilisé pour évaluer les performances des modèles :\n",
    "   - Rappel : Mesure de la capacité à identifier correctement la classe minoritaire.\n",
    "   - Précision : Évaluation de la fiabilité des prédictions positives.\n",
    "   - F1-score : Moyenne harmonique du rappel et de la précision.\n",
    "   - AUC-PR : Évaluation du compromis précision-rappel, particulièrement pertinente pour nos jeux de données fortement déséquilibrés.\n",
    "   - Autres mesures issues de la matrice de confusion comme l'accuracy et l'AUC-ROC.\n",
    "   - Mesure du temps d'execution de la phase \"fit\", c'est à dire l'entrainement pour chaque dataset.\n",
    "\n",
    "    Une mesure indicative de l'utilisation de la ram a été également estimée. Il s'agissait de comparer la taille de mémoire utilisée avant, et juste à la fin d'un entrainement.\n",
    "   \n",
    "- **Techniques de rééquilibrage** :\n",
    "\n",
    "  Après un premier lancer simple des différents algorithmes (basiques et ensemblistes) sur les datasets nettoyés et sans équilibrage des classes, deux autres lancers succéderont :\n",
    "  - Le deuxième appliquera les mêmes algorithmes sur des datsets équilibrés par oversampling SMOTE.\n",
    "  - Le troisième appliquera les mêmes algorithmes sur des datasets non équilibrés, mais en pondérant le poids des erreurs en fonction de la prépondérance de la classe. Ceci se fait via des paramètres comme \"class_weight='balanced'\"\n",
    " \n",
    "Un dernier Lancer choisira deux méthodes parmis celles testées, pour maximiser leurs performances en combinant diverses approches.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9856d178-9024-4ef6-a9f8-55e0208cf9ce",
   "metadata": {},
   "source": [
    "### 3.4 Configuration des hyperparamètres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80687d01-e68b-46db-9cf4-041b9f0b4f2c",
   "metadata": {},
   "source": [
    "Les plages d'hyperparamètres suivantes ont été servies à la validation croisée pour qu'elle ajuste la valeur adéquate en fonction de la métrique du rappel:\n",
    "\n",
    "- **Lancer sans rééquilibrage** :\n",
    "\n",
    "    a) Modèles de base :\n",
    "    - Régression logistique et SVM linéaire : C ∈ {0.001, 0.01, 0.1, 1, 10}\n",
    "    - Arbre de décision : max_depth ∈ {3, 5, 10, 20, None}\n",
    "    - k-NN : n_neighbors ∈ {3, 5, 7, 9, 11}\n",
    "    - MLP : alpha ∈ {10, 1, 0.1, 0.01, 0.001}\n",
    "    \n",
    "    b) Modèles ensemblistes :\n",
    "    - Bagging, Random Forest, Gradient Boosting : n_estimators ∈ {10, 20, 50, 100, 200}\n",
    "    - AdaBoost : n_estimators ∈ {10, 20, 50, 100, 200}, learning_rate ∈ {0.01, 0.1, 0.5, 1.0}\n",
    "    - Stacking : C du méta-classificateur ∈ {0.001, 0.01, 0.1, 1, 10}\n",
    "\n",
    "- **Lancer avec SMOTE** :\n",
    "\n",
    "    Les mêmes plages d'hyper-paramètres que pour le lancer sans rééquilibrage ont été utilisées, mais cette fois en appliquant SMOTE aux données d'entraînement.\n",
    "\n",
    "- **Lancer avec pondération des classes** :\n",
    "\n",
    "    a) Modèles de base :\n",
    "    - Mêmes plages que précédemment, mais avec class_weight='balanced'\n",
    "    \n",
    "    b) Modèles ensemblistes :\n",
    "    - Mêmes plages que précédemment, avec class_weight='balanced' pour les estimateurs compatibles\n",
    "\n",
    "- **Lancer avec modèles avancés** :\n",
    "\n",
    "    a) Random Forest avec pondération et multi-fine-tuné :\n",
    "    - n_estimators ∈ {200, 300, 500}\n",
    "    - max_depth ∈ {20, None}\n",
    "    - min_samples_split ∈ {2, 5}\n",
    "    - min_samples_leaf ∈ {1, 2}\n",
    "    - max_features ∈ {'sqrt', 'log2'}\n",
    "    - criterion ∈ {'gini', 'entropy'}\n",
    "    \n",
    "    b) XGBoost avec pondération  et multi-fine-tuné:\n",
    "    - n_estimators ∈ {100, 200, 500}\n",
    "    - learning_rate ∈ {0.01, 0.1, 0.2}\n",
    "    - max_depth ∈ {3, 5, 10}\n",
    "    - gamma ∈ {0, 0.1, 0.3}\n",
    "    - sub_sample ∈ {0.8, 1.0}\n",
    "\n",
    "Cette approche systématique permet de partir d'une base de comparaison commune avant d'appliquer des techniques plus avancées, tout en respectant l'ordre de comparabilité dû aux hyperparamètres."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e1d685-1c8f-445a-a120-c1e7c5ada09d",
   "metadata": {},
   "source": [
    "## 4. Résultats\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091cc1ba-2637-43c3-9819-ecb70b470924",
   "metadata": {},
   "source": [
    "### 4.1 Vue d'ensemble des performances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dec16e8-da71-4405-aa00-f5f935a68e50",
   "metadata": {},
   "source": [
    "Notre étude comparative des différentes méthodes de classification sur 28 jeux de données déséquilibrés a révélé des tendances significatives en termes de performance. L'analyse s'est concentrée sur des métrique pertinentes pour des données déséquilibrées : Le F1_score, le rappel  et l'AUC-PR (Area Under the Precision-Recall Curve). Voici un tableau récapitulatif de la performance moyenne des différents algorithmes sur tous les datasets, ce tableau est trié par ordre décroissant de performance sur F1_score ensuite Recall ensuite AUC_PR:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90dc505-0a20-4ec1-ac3f-44b5382a95cb",
   "metadata": {},
   "source": [
    "| Méthode | Accuracy | Precision | Recall | F1-score | AUC-ROC | AUC-PR | Training Time |\n",
    "|---------|----------|-----------|--------|----------|---------|--------|---------------|\n",
    "| Bagging (SMOTE) | 0.902461 | 0.712400 | 0.730658 | 0.714346 | 0.898613 | 0.733351 | 11.827343 |\n",
    "| Stacking (SMOTE) | 0.897605 | 0.699270 | 0.741267 | 0.713056 | 0.909534 | 0.741371 | 6.819120 |\n",
    "| Random Forest (SMOTE) | 0.901836 | 0.720510 | 0.715625 | 0.711027 | 0.915047 | 0.760684 | 1.226988 |\n",
    "| Gradient Boosting (SMOTE) | 0.870541 | 0.669978 | 0.834988 | 0.703735 | 0.902723 | 0.736917 | 6.655989 |\n",
    "| RF (weighted, fine-tuned) | 0.869344 | 0.635234 | 0.861845 | 0.698980 | 0.914696 | 0.770042 | 62.967726 |\n",
    "| Bagging | 0.908204 | 0.742837 | 0.667037 | 0.697453 | 0.889295 | 0.751663 | 4.821189 |\n",
    "| XGBoost (weighted, fine-tuned) | 0.865929 | 0.646359 | 0.828822 | 0.695847 | 0.906995 | 0.743723 | 22.844824 |\n",
    "| Random Forest | 0.914418 | 0.763278 | 0.652635 | 0.692095 | 0.895666 | 0.761383 | 0.950948 |\n",
    "| Gradient Boosting | 0.907725 | 0.774261 | 0.664689 | 0.689820 | 0.908736 | 0.760447 | 3.518946 |\n",
    "| Random Forest (Weighted) | 0.862453 | 0.627007 | 0.856235 | 0.687864 | 0.904394 | 0.763200 | 1.144079 |\n",
    "| Bagging (Weighted) | 0.906089 | 0.749385 | 0.649437 | 0.680992 | 0.883085 | 0.742406 | 5.071231 |\n",
    "| Stacking (Weighted) | 0.851803 | 0.617313 | 0.867978 | 0.677818 | 0.916612 | 0.741051 | 8.500697 |\n",
    "| Stacking (multi) | 0.909194 | 0.711080 | 0.645041 | 0.666985 | 0.921778 | 0.759478 | 3.196537 |\n",
    "| AdaBoost | 0.899623 | 0.711821 | 0.657802 | 0.663114 | 0.870385 | 0.693551 | 5.215613 |\n",
    "| AdaBoost (Weighted) | 0.878453 | 0.682912 | 0.645128 | 0.660586 | 0.782565 | 0.591088 | 3.545089 |\n",
    "| k-NN (SMOTE) | 0.838237 | 0.598545 | 0.797662 | 0.654415 | 0.882934 | 0.679142 | 0.601345 |\n",
    "| Decision Tree (SMOTE) | 0.822136 | 0.602896 | 0.812062 | 0.652068 | 0.836497 | 0.605372 | 0.567774 |\n",
    "| Decision Tree (Weighted) | 0.815587 | 0.591188 | 0.816153 | 0.647877 | 0.832827 | 0.613575 | 0.384423 |\n",
    "| MLP (SMOTE) | 0.833257 | 0.597231 | 0.822331 | 0.646959 | 0.894184 | 0.691412 | 0.519395 |\n",
    "| Decision Tree | 0.876803 | 0.672292 | 0.649198 | 0.646540 | 0.811192 | 0.605907 | 0.393592 |\n",
    "| k-NN | 0.874893 | 0.703643 | 0.616083 | 0.645483 | 0.843386 | 0.672738 | 0.456229 |\n",
    "| Logistic Regression (SMOTE) | 0.821698 | 0.574135 | 0.835937 | 0.637018 | 0.880968 | 0.674968 | 0.476985 |\n",
    "| SVM (SMOTE) | 0.826253 | 0.580255 | 0.824599 | 0.635498 | 0.885078 | 0.678601 | 0.645203 |\n",
    "| AdaBoost (SMOTE) | 0.771508 | 0.576654 | 0.883617 | 0.634611 | 0.861879 | 0.639701 | 9.487567 |\n",
    "| SVM (Weighted) | 0.789247 | 0.522687 | 0.860006 | 0.604647 | 0.886868 | 0.681713 | 0.447927 |\n",
    "| MLP | 0.886271 | 0.710151 | 0.565811 | 0.600892 | 0.890884 | 0.704159 | 0.453180 |\n",
    "| Logistic Regression | 0.878089 | 0.691439 | 0.574947 | 0.596974 | 0.864485 | 0.688063 | 0.666701 |\n",
    "| Stacking (SVM) | 0.877660 | 0.684113 | 0.561107 | 0.593042 | 0.892727 | 0.697352 | 3.033375 |\n",
    "| Logistic Regression (Weighted) | 0.758756 | 0.502223 | 0.866096 | 0.587524 | 0.878094 | 0.675005 | 0.400183 |\n",
    "| SVM | 0.876923 | 0.678859 | 0.567243 | 0.586711 | 0.855987 | 0.674779 | 0.427128 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b98183-7eb0-4400-880a-d46bb159c942",
   "metadata": {},
   "source": [
    "Sans surprise, les méthodes ensemblistes ont en moyenne de meilleurs résultats que les méthodes non ensemblistes:\n",
    "- Bien que très bien classés en Accuracy, SVM et Logistic_Regression sont les moins bien classés en F1_score et en recall.\n",
    "- Bagging, stacking, Random_Forest et Boosting sont en haut du classement sur le f1_score et le recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d483f364-e518-4448-9d5f-c794465a54e2",
   "metadata": {},
   "source": [
    "Essayons d'affiner notre appréciation en visualisant les barres de performance de chaque méthode par groupe de datasets.\n",
    "\n",
    "Le groupe 1 est constitué de 7 datasets, ayant une classe majoritaire ne dépassant pas les 60%. Il est censé représenter le groupe de données équilibrées. Le groupe 2 est son complémentaire sur l'ensemble des datasets, c'est à dire les 21 datasets ayant une classe majoritaire dépassant les 60%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d439bc6d-3ac4-4023-9573-323ff0fdc541",
   "metadata": {},
   "source": [
    "Voici les resultats globaux de la moyenne du Recall par méthode et par groupe:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c2ac0b-2647-4c54-b6e4-7806368a1093",
   "metadata": {},
   "source": [
    "![](./graphiques/bar_plot_mean_recall_per_method_per_group.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723369e5-16ed-4e27-afb6-870a87150c5a",
   "metadata": {},
   "source": [
    "Les méthodes d'ensembles montrent clairement de meilleurs performances en particuliers sur les datasets déséquilibrés.\n",
    "\n",
    "Notons que le stacking avec plusieurs SVMs linéaires n'a pas pu bénéficier d'un résultat significativement meilleur qu'un SVM simple sur les données déséquilibrées, il a même montré des résultats moins bons sur les données équilibrées.\n",
    "\n",
    "Pour mieux le voir, voici le même graphique mais trié par performance de Recall sur les données déséquilibrées :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b066b74-b5ed-415f-942e-6e941c81e524",
   "metadata": {},
   "source": [
    "![](./graphiques/barplot_mean_recall_g1g2_sortedg2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb2ff96-ca55-4fd1-a34d-d96ecaed993d",
   "metadata": {},
   "source": [
    "### 4.2 Impact des techniques de rééquilibrage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9697deb7-f08d-4896-b581-73b86a918b03",
   "metadata": {},
   "source": [
    "#### 4.2.1 Amélioration globale des performances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b986284b-b18b-4318-a31c-2e34557e23e7",
   "metadata": {},
   "source": [
    "Nous prenons ici trois algorithmes ensemblistes et trois algorithmes non ensemblistes. Nous étudions l'effet du rééquilibrage par oversampling smote, et par pondération des poids de l'erreur sur la prédiction finale dans les datasets déséquilibrés.\n",
    "\n",
    "Le graphique représente pour chaque algorithme trois résultats:\n",
    "- En vert la performance recall de la version classique de la méthode.\n",
    "- En rouge la performance avec pondération des poids de l'erreur.\n",
    "- En bleu la version sur-échantillonnée.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9adac96-0367-457c-8130-155cf3cc8093",
   "metadata": {},
   "source": [
    "![](./graphiques/bar_plot_groups_classic_smote_weighted_recall.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ec32ed-cd8b-41d3-a20f-6d2b665b4df7",
   "metadata": {},
   "source": [
    "Dans tous les algorithmes, les technique de rééquilibrage ont permis une amélioration significative des résultats:\n",
    "\n",
    "- Pour les algorithmes non ensemblistes, Les deux techniques semblent avoir un effet du même ordre sur le résultat en particulier pour l'arbre de décision qui semble avoir bénéficié de façon équivalente de l'une ou l'autre.\n",
    "\n",
    "- Adaboost a beaucoup plus bénéficié de SMOTE, ceci s'explique peut être par le fait que la pondération des poids de l'erreur était intégrée à ses estimateurs, des arbre de décision de faible profondeur.\n",
    "\n",
    "- Random_Forest et le stacking_multi (familles variées de base-learners)  ont plus tiré profît de la pondération du poids de l'erreur.\n",
    "\n",
    "Dans l'ensemble, sur des datasets de classification binaire dont la classe majoritaire dépasse les 60%, en moyenne tous les algorithmes améliorent leurs résultats avec le rééquilibrage. Une meilleure efficacité semble être du côté de la sensibilité au coût des erreurs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4580f2c-05d3-4972-b288-65c3c89dff52",
   "metadata": {},
   "source": [
    "### 4.2.2 Cas des datasets fortement déséquilibrés"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515c5b57-50a3-483f-aec9-c76630d546cf",
   "metadata": {},
   "source": [
    "Il existe un seuil de déséquilibre au delà duquel nos algorithmes se sont confronté à l'impossibilité de bien prédire le bon label, visualisons la Heatmap du score F1 des toutes les méthodes pour tous les datasets:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0122bf43-ca84-46a3-a7d5-b6d70edb9847",
   "metadata": {},
   "source": [
    "![](./graphiques/heatmap_f1_score.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbcb181-b3df-4378-b146-214ca58bac8b",
   "metadata": {},
   "source": [
    "Rappelons également les proportions de la classe positive dans chaque dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbc1bc9-d856-487b-adc5-14b3a797ae53",
   "metadata": {},
   "source": [
    "| Nom     | sonar   | balance | splice  | australian | heart   | hayes   | bupa    | spambase | autompg | wdbc    |\n",
    "|---------|---------|---------|---------|------------|---------|---------|---------|----------|---------|---------|\n",
    "| Ratio   | 0.466346| 0.460800| 0.449348| 0.444928   | 0.444444| 0.434783| 0.416422| 0.398954 | 0.375000| 0.372583|\n",
    "\n",
    "| Nom     | iono    | pima    | wine    | glass   | newthyroid | german  | vehicle | segmentation | abalone8| bankm |\n",
    "|---------|---------|---------|---------|---------|------------|---------|---------|--------------|---------|-------|\n",
    "| Ratio   | 0.357143| 0.348958| 0.331461| 0.323944| 0.302326   | 0.300000| 0.235225| 0.142857     | 0.135983| 0.116985|\n",
    "\n",
    "| Nom     | yeast3  | satimage| pageblocks | libras  | wine4   | yeast6  | abalone17 | abalone20 |\n",
    "|---------|---------|---------|------------|---------|---------|---------|-----------|-----------|\n",
    "| Ratio   | 0.111493| 0.097280| 0.095132   | 0.072727| 0.038999| 0.024088| 0.013886  | 0.006225  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ee6309-0e68-43b2-bb67-3b24dd9146be",
   "metadata": {},
   "source": [
    "Pour des datasets comme wine4 (ratio de classe 1 de seulement 0.038), presque toutes les méthodes échouent, sauf pour quelques-unes comme XGBoost_weighted_multi_finetuned et RF_weighted_multi_finetuned, qui obtiennent des scores F1 légèrement supérieurs, mais tout de même très faibles. Il en est de même ou pire pour les datasets plus déséquilibrés, et ce malgré les techniques de rééquilibrage. Cela montre que ces datasets sont particulièrement difficiles à traiter, même avec des techniques avancées."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c2b11f-bac6-4164-abef-cc362e571207",
   "metadata": {},
   "source": [
    "### 4.3 Coût computationnel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a953f3b-3ee8-4985-866f-452318e7d3d1",
   "metadata": {},
   "source": [
    "Pour l'aspect coût computationnel, le temps cumulé d'entrainement sur tous les datasets est une information éloquante :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc931d3-c677-4fc4-8875-4f4e4c423ab2",
   "metadata": {},
   "source": [
    "![](./graphiques/training_time.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2527b473-0c0f-4d35-96d6-068f32d6c2cd",
   "metadata": {},
   "source": [
    "Les algorithmes d'ensemble (Bagging, AdaBoost, Gradient Boosting, Stacking) occupent clairement les premières places en termes de temps d'entraînement. Ces méthodes nécessitent plus de temps, notamment les versions avec fine-tuning, car elles reposent sur la combinaison de multiples modèles, qui sont souvent plus complexes à entraîner. En particulier, les méthodes comme Random Forest et XGBoost, lorsqu'elles sont ajustées et pondérées, nécessitent des calculs intensifs en raison du nombre d'estimateurs et des processus itératifs de boosting.\n",
    "\n",
    "Méthodes non-ensemblistes : À l'opposé, des algorithmes plus simples comme Logistic Regression, SVM, k-NN, et Decision Tree prennent beaucoup moins de temps pour l'entraînement. Ces méthodes ne reposent pas sur l'agrégation de plusieurs modèles, ce qui réduit leur coût computationnel. Cela les rend plus rapides à entraîner, mais potentiellement moins performantes dans des situations complexes ou avec des données déséquilibrées."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6169c840-fae9-42ba-8a7d-34874ebbdb92",
   "metadata": {},
   "source": [
    "### 4.4 Modèles avancés "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bd374c-2354-412f-a746-9c522766102e",
   "metadata": {},
   "source": [
    "Ce graphe fait la synthèse de la performance en F1_score moyen de toutes les méthodes :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca02f6f8-1b45-447c-b248-1c619e5e13fc",
   "metadata": {},
   "source": [
    "![](./graphiques/perf_moyenne_globale.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d53a23-b4c7-4af4-ab5d-e65998b4b363",
   "metadata": {},
   "source": [
    "La méthode XGBoost_Weighted_multi_finetuned et RF_Weighted_multi_finetuned, bien que bien classées ne prennent pas la tête du classement. Sur le critère du F1_score, trois algorithmes ayant bénéficié de l'équilibrage des données par smote qui sont en tête. Il s'agit de trois méthodes ensemblistes :\n",
    "- Bagging avec smote\n",
    "- Stacking avec smote\n",
    "- Random Forest avec smote\n",
    "  \n",
    "Ce résultat pose la question de la pertinence du finetuning poussé rapporté à son coût calculatoire. En effet ces deux méthodes ont consommé plus de la moitié du temps total d'exécution des cross_validations. La random forest, en particulier sur le finetuning des critères de split (gini, entropy) a été très gourmande en ressources. Ce sont certainement des considérations à prendre en compte pour une application non académique pouvant être limitée par le temps ou les ressources physiques. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb70f483-e499-4d63-a086-2c5a1eef6301",
   "metadata": {},
   "source": [
    "## 5. Conclusion et perspectives\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cea1d4c-e6e2-4fea-a1ab-aa8ce474350c",
   "metadata": {},
   "source": [
    "\n",
    "Notre étude comparative des méthodes d'ensemble et des techniques de rééquilibrage sur 28 jeux de données déséquilibrés a mis en évidence plusieurs points :\n",
    "\n",
    "**Performance des méthodes d'ensemble** : Les algorithmes comme Bagging, Random Forest et les méthodes de Boosting ont généralement obtenu de meilleurs résultats en termes de F1-score, rappel et AUC-PR, notamment sur les datasets fortement déséquilibrés.\n",
    "\n",
    "**Efficacité des techniques de rééquilibrage** : SMOTE et la pondération des classes ont amélioré les performances de la plupart des classifieurs. La pondération des classes s'est révélée particulièrement efficace pour certains algorithmes d'ensemble.\n",
    "\n",
    "**Coût computationnel** : Les méthodes d'ensemble, bien que plus performantes, ont montré un temps de calcul significativement plus élevé, surtout dans leurs versions ajustées.\n",
    "\n",
    "**Limites sur les données très déséquilibrées** : Pour les jeux de données avec un ratio de classe minoritaire inférieur à 5%, même les méthodes avancées ont montré des performances limitées.\n",
    "\n",
    "Plusieurs pistes pourraient être explorées pour approfondir cette étude :\n",
    "\n",
    "**Techniques de sous-échantillonnage** : partir plutôt sur le sous-échantillonnage de la classe majoritaire.\n",
    "\n",
    "**Approches combinées** : La combinaison de techniques de sur-échantillonnage et de sous-échantillonnage.\n",
    "\n",
    "**Algorithmes spécifiques** : L'intégration d'algorithmes conçus pour les problèmes déséquilibrés, comme ADASYN ou BorderlineSMOTE.\n",
    "\n",
    "**Méthodes basées sur les coûts** : Une exploration plus poussée des méthodes basées sur les coûts.\n",
    "\n",
    "\n",
    "Ces pistes pourraient permettre d'améliorer les performances sur les datasets très déséquilibrés et d'approfondir notre compréhension des possibilités d'ajustement entre les caractéristiques des données, les algorithmes de classification et les techniques de rééquilibrage."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
